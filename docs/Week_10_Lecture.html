<div id="dp-wrapper" class="dp-wrapper">
    <div style="background: #58595B; margin-bottom: 15px; color: #ffffff; text-align: center;"><img src="https://utk.instructure.com/courses/242597/files/28448703/download" alt="Week 10 Fixed Effects Banner" width="100%" height="auto" data-api-endpoint="https://utk.instructure.com/api/v1/courses/242597/files/28448703" data-api-returntype="File" /></div>
    <hr style="border-top: 3px solid orange;" />
    <h2 style="text-align: center;"><strong>Estimating Causal Effects with Fixed Effects Models</strong></h2>
    <hr style="border-top: 3px solid orange; margin-bottom: 25px;" />
    <div class="content-box pad-box-mini border border-trbl border-round" style="background-color: #f8f8f8; padding: 15px; margin-bottom: 20px;">
        <h3><strong>The Need for Fixed Effects: Beyond ITS and RD</strong></h3>
        <p>In the past few weeks, we&rsquo;ve explored how two research designs&mdash;Regression Discontinuity (RD) and Interrupted Time Series (ITS)&mdash;can help us get closer to causal claims when working with observational data, which is usually plagued by our inability to make true &ldquo;like to like&rdquo; comparisons. In RD, we relied on policy- or program-generated cutoffs to create groups that were similar except for receiving the treatment. For example, to estimate the impact of receiving welfare benefits (X) on educational attainment (Y), we focused on comparing individuals who just barely qualified (X = 1) to those who just barely missed (X = 0). Because those two groups are so similar, the comparison becomes much more credible than a typical observational regression.</p>
        <p>ITS took a different approach. Instead of comparing one unit to another (City A vs. City B), ITS compares a single unit to itself right before and after a major, well-timed change&mdash;such as a new law or program implementation. Time-series data allow us to look for a sharp &ldquo;break&rdquo; at the exact moment of intervention and ask whether the pattern of outcomes changed in response. While our main example focused on a single unit, multiple-unit ITS designs are also possible.</p>
        <p>Both RD and ITS create remarkably clean comparisons and address the &ldquo;like to like&rdquo; problem we discussed in Weeks 3 and 4. But they share an important limitation: <strong>they only work under very specific conditions.</strong> RD requires a meaningful cutoff. ITS requires a sharp, well-timed intervention. Both are fundamentally &ldquo;intervention-based&rdquo; designs&mdash;situations where something sudden and powerful happens and we want to see whether the outcome changes.</p>
        <p>A lot of policy questions can be framed this way&mdash;Did a new policy work? Did access to a program lead to a benefit?&mdash;but many cannot. Many public policy and administrative questions involve ongoing processes, gradual changes, or relationships between variables that don&rsquo;t map neatly onto a cutoff or a single intervention moment.</p>
        <p>This is where <strong>Fixed Effects (FE)</strong> becomes incredibly useful. FE doesn&rsquo;t need a cutoff. It doesn&rsquo;t need a sudden shock. Instead, it takes advantage of something we have in abundance in public administration: <strong>panel data</strong>&mdash;data structures that contain multiple observations of multiple units over time. For example: data on many cities (units) measured across many years (time).</p>
        <p>Every unit we study&mdash;cities, agencies, school districts, nonprofits&mdash;has stable characteristics that shape outcomes: organizational culture, long-standing resource levels, leadership history, demographic makeup, and so on. These <strong>unit-based confounders</strong> are the biggest barrier to making causal claims in cross-sectional analysis because we rarely observe them directly.</p>
        <p>Fixed Effects offers an elegant solution: if we observe a unit repeatedly, we can compare it <em>to itself</em>, eliminating everything about that unit that does not change over time. <strong>WE STILL DO HAVE TO WORRY ABOUT CONFOUNDERS THAT CHANGE QUICKLY OVER TIME&mdash;but we get to rid ourselves of those that don&rsquo;t. And that&rsquo;s a big deal. </strong></p>
        <p>This makes FE not just powerful, but <strong>remarkably flexible</strong>. Yes, we can use FE to study interventions if units experience meaningful change. But we can also use it to study questions like:</p>
        <ul>
            <li>how staffing changes relate to outcomes</li>
            <li>how budget fluctuations influence performance</li>
            <li>whether policies are more effective in some agencies than others</li>
            <li>or essentially any question where we want to &ldquo;hold the unit constant&rdquo;</li>
        </ul>
        <p>This is why our arc from <strong>RD &rarr; ITS &rarr; FE</strong> is intentional. RD and ITS are precise tools designed for specific kinds of scenarios. Fixed Effects, by contrast, is a broad, flexible framework&mdash;one of the most widely used approaches in applied policy research&mdash;because it directly solves the problem we face constantly: <strong>units differ, and those differences bias simple regressions.</strong></p>
        <p>That said, FE is not a panacea. It comes with one major requirement: <strong>your key variables (both X and Y) must vary over-time within each unit</strong>. If nothing changes, FE has nothing to work with. So while FE &nbsp;is incredibly useful, it is still imperfect.</p>
        <p>For example:</p>
        <ul>
            <li>If you want to study how an officer&rsquo;s race or gender affects job satisfaction&mdash;and you have beautiful panel data from a police department&mdash;too bad. Race and gender <strong>do not</strong> vary over time for individuals. FE cannot estimate their effects.</li>
            <li>But if you want to study how the racial composition of police departments affects departmental performance&mdash;and you have panel data tracking many departments over many years&mdash;that <em>does</em> work. Departmental demographics <strong>do change</strong> over time, giving FE something to leverage.</li>
        </ul>
        <p>Okay&mdash;that introduction was too long. Long story short, FE models are incredibly flexible and powerful. BUT they can only be used to study things that shift&mdash;at least theoretically&mdash;within units over time. If they meet that ever so basic requirement, a FE model just might be the model you&rsquo;re looking for. Let&rsquo;s get to it.</p>
    </div>
    <hr style="border-top: 3px solid orange;" />
    <div class="content-box pad-box-mini border border-trbl border-round" style="background-color: #f8f8f8; padding: 15px;">
        <h3><strong>What FE Models Do in Principle (NO MATH&hellip;YET)</strong></h3>
        <p>Now that we&rsquo;ve established why FE models are useful, we can focus on what they actually do. The core idea is straightforward: <strong>FE models isolate within-unit changes over time.</strong> Instead of comparing one unit to another&mdash;which is where cross-sectional analysis gets into trouble&mdash;FE compares each unit <strong>to itself</strong>, across the years (or months) we observe it.</p>
        <p>To see why this works, imagine tracking the same city, agency, or school district across time. Each unit has certain stable characteristics that never really change (or at least change SUPER slowly): political culture, long-standing resource levels, community demographics, leadership history. These factors might strongly influence the outcome we care about, but because they do not change from year to year, they can&rsquo;t explain why a unit&rsquo;s outcomes go up or down <em>over time</em>. FE takes advantage of that structure.</p>
        <p>In a FE model, we effectively subtract out each unit&rsquo;s long-run baseline (its average level of the outcome across all the years in the dataset). Once we do that, the only remaining variation is the &ldquo;ups and downs&rdquo; within each unit:</p>
        <ul>
            <li>When this agency increases its staffing above its usual level, does its performance rise above its usual level?</li>
            <li>When this city&rsquo;s budget tightens relative to its own history, does crime or service quality shift relative to its own baseline?</li>
        </ul>
        <p>That&rsquo;s the comparison FE is built on: <strong>higher than usual vs. lower than usual for the same unit</strong>.</p>
        <p>This also highlights FE&rsquo;s biggest requirement: the key variables (X and Y) must actually change over time within each unit. If a variable never changes&mdash;like a person&rsquo;s race or gender, or a school district&rsquo;s founding year&mdash;it gets absorbed into the unit&rsquo;s fixed effect and cannot be estimated. But variables that do fluctuate (budgets, staffing levels, demographics, leadership turnover, caseloads, policies) are exactly what FE is designed to analyze.</p>
        <p>The beauty of the FE approach is that it allows us to &ldquo;hold the unit constant&rdquo; without needing to measure or observe its stable characteristics. Everything about a unit that does not change over time is controlled for <strong><em>automatically</em></strong>. What remains is the meaningful, within-unit variation: we get to see if THAT part matters.&nbsp; Cool, right?</p>
    </div>
    <hr style="border-top: 3px solid orange;" />
    <div class="content-box pad-box-mini border border-trbl border-round" style="background-color: #f8f8f8; padding: 15px;">
        <h3><strong></strong><strong>Some Examples</strong></h3>
        <p>Okay okay, let&rsquo;s work through some hypothetical examples where FE models could be applied to make this all feel a little more concrete. In each case, the notice that our TWO THINGS stays the same: (i) <strong>we observe the same units (again, cities, people, states, organizations, etc.) repeatedly over time (panel data)</strong>, (ii) <strong>and the things that we care about CAN theoretically vary within those units.</strong> If you have data that does not match (not panel) or variables that cannot plausibly vary within units&hellip; no dice. If you do, you just may have a FE model to run, my friend.</p>
        <p>Below are several examples, along with short descriptions of what the data structures typically look like.</p>
        <p><strong>Example 1: Staffing and Public Safety (City-Year Panel Data)</strong></p>
        <ul>
            <li><em>Data structure:</em> Data on 300 cities observed yearly from 2005&ndash;2022.</li>
            <li>Question<strong>:</strong> Does changing the number of police officers in a city affect crime rates?</li>
            <li>Cities differ in countless stable ways&mdash;history, politics, long-run economic conditions. FE handles that by comparing each city to itself over time. If staffing rises and falls year to year, FE can isolate how crime changes in those periods relative to the city&rsquo;s own baseline.</li>
        </ul>
        <p><strong>Example 2: School Funding and Student Achievement (District-Year Panel)</strong></p>
        <ul>
            <li><em>Data structure:</em> Data on all school districts in a state observed annually for a decade.</li>
            <li>Question<strong>:</strong> Do changes in school funding affect student outcomes within districts?</li>
            <li>Districts vary in capacity, resources, demographics, and leadership history. FE cuts through those stable differences. If per-pupil spending fluctuates over time within a district, FE lets us examine how test scores respond relative to that district&rsquo;s long-run pattern.</li>
        </ul>
        <p><strong>Example 3: Agency Performance and Turnover (Agency-Quarter Panel)</strong></p>
        <ul>
            <li><em>Data structure:</em> Data on 80 state agencies measured each quarter from 2012&ndash;2020.</li>
            <li>Question<strong>:</strong> Does staff turnover affect agency performance?</li>
            <li>Agencies differ deeply in culture, mission, and baseline staffing&mdash;traits that never vanish and are difficult to measure. But turnover does change quarter to quarter. FE compares each agency to itself across time, focusing on periods when turnover rises or falls relative to its own average.</li>
        </ul>
        <p><strong>Example 4: Housing Costs and Neighborhood Stability (Neighborhood-Year Panel)</strong></p>
        <ul>
            <li><em>Data structure:</em> A dataset with hundreds of neighborhoods tracked each year from 2010&ndash;2021.</li>
            <li>Question<strong>:</strong> Do rising housing costs destabilize neighborhoods?</li>
            <li>Neighborhoods differ in stable ways&mdash;history, layout, networks, long-term investment patterns. FE removes these differences by design. If rents, eviction rates, or investment shifts occur within a neighborhood across years, FE uses that variation to estimate their association with stability.</li>
        </ul>
        <p><strong>Example 5: Program Reach and Nonprofit Outcomes (Organization-Year Panel)</strong></p>
        <ul>
            <li><em>Data structure:</em> Data on thousands of nonprofits observed annually across a six-year period.</li>
            <li>Question<strong>:</strong> Does increased program reach improve organizational outcomes?</li>
            <li>Nonprofits differ in mission, donor networks, founding histories, and reputations&mdash;factors that don&rsquo;t change much and rarely get measured well. But program reach, staffing, and funding often do change. FE leverages this to compare a nonprofit to itself over time.</li>
        </ul>
        <p><em>Are you getting why FE models are SO WIDELY used<strong>?</strong></em><strong> </strong>They ask so little and give so much. All we need is (i) panel data, and (ii) time varying variables. If we have that, we get a model that can rule out a whole hose of time-invariant confounders. We still 100% have to worry about&nbsp; confounding variables that can move along with our X and Y. But getting to eschew ourselves of the ones that don&rsquo;t move (and those that don&rsquo;t move quickly) is an incredibly powerful.</p>
    </div>
    <hr style="border-top: 3px solid orange;" />
    <div class="content-box pad-box-mini border border-trbl border-round" style="background-color: #f8f8f8; padding: 15px;">
        <h3><strong>What FE Models Are Actually Doing</strong></h3>
        <p>Okay, now that we&rsquo;ve seen WHY FE models can be helpful (and in what contexts), we can take a closer look at how the model actually works. The goal here (and in the course more generally) isn&rsquo;t to turn you into a full-on econometrician, but to help you understand what the model is doing conceptually, so that when you estimate it, the logic feels natural. We need a baby bit of math here.</p>
        <p>Let&rsquo;s start with the &ldquo;official&rdquo; version of the model and then move quickly to the much more intuitive version that truly captures the FE idea.</p>
        <h4><strong>The Usual FE Model </strong></h4>
        <p>The formal FE model looks like a standard regression, but with one big addition:</p>
        <pre style="background-color: #e0e0e0; padding: 10px; border-radius: 5px; text-align: center;"><code>Y<sub>it</sub> = &alpha;<sub>i</sub> + &beta;X<sub>it</sub> + &epsilon;<sub>it</sub></code></pre>
        <p>If you squint at it, it looks super similar to a basic regression but with a small difference. If you look at the alpha term&mdash;its slightly different than normal&mdash;its got a little &ldquo;i&rdquo; dangling. That &nbsp;term is doing a lot of work. It means that instead of a single intercept for the ENTIRE EQUATION (i.e., for all groups, units, etc.) every &ldquo;unit&rdquo; (city, state, etc.) gets its own intercept. That little i is doing a TON of work for us.&nbsp;</p>
        <p>Think of as the unit&rsquo;s personality (its long-term culture, demographics, typical funding level, political climate, and so on). These are the things we almost never measure well, but that absolutely shape the outcome (and likely the IV too&mdash;which is why it&rsquo;s a problem).</p>
        <p>In ordinary regressions, these stable differences create massive confounding. The beauty of FE is that the model accounts for them automatically.</p>
        <p>But this equation doesn&rsquo;t really show how. For that, we need to look at the intuitive version.</p>
        <h4><strong>The Intuitive Version: Subtracting Each Unit From Itself</strong></h4>
        <p>Here&rsquo;s what FE is actually doing behind the scenes: It subtracts each unit&rsquo;s average from all of its observations. This gives us the &ldquo;demeaned&rdquo; form of the model:</p>
        <pre style="background-color: #e0e0e0; padding: 10px; border-radius: 5px; text-align: center;"><code>Y<sub>it</sub> - Ȳ<sub>i</sub> = &beta;(X<sub>it</sub> - X̄<sub>i</sub>) + (&epsilon;<sub>it</sub> - &epsilon;̄<sub>i</sub>)</code></pre>
        <p>This is FE in its purest (at least IMO) form.</p>
        <ul>
            <li>We take the outcome for the unit in a given year</li>
            <li>We subtract the unit&rsquo;s <strong>own average outcome</strong></li>
            <li>We do the same for the explanatory variable</li>
            <li>Then we regress those deviations on each other</li>
        </ul>
        <p>What this leaves us with is a picture of how the unit moves <strong>relative to itself</strong> over time.</p>
        <p>It is no longer City A vs. City B. It is <strong>City A vs. City A in different years</strong>.</p>
        <p>Once we subtract each unit&rsquo;s long-run baseline, all of those stable, hard-to-measure differences disappear (culture, wealth, leadership quality, geography): they simply fall out of the equation.</p>
        <p>This is why FE is so powerful: it removes the biggest sources of bias <em>without us ever needing to measure them</em>.</p>
        <h4><strong>What the Subtraction Means (A Story)</strong></h4>
        <p>Let&rsquo;s make this tangible. Imagine one city (just one). Call it City A (imaginative I know).</p>
        <p>Over three years, you observe its crime rate (Y) and staffing (X):</p>
        <ul>
            <li>Year 1: crime = 50; staffing = 10</li>
            <li>Year 2: crime = 48; staffing = 12</li>
            <li>Year 3: crime = 46; staffing = 14</li>
        </ul>
        <p>If we calculate City A&rsquo;s averages:</p>
        <ul>
            <li>Mean crime = 48</li>
            <li>Mean staffing = 12</li>
        </ul>
        <p>The FE transformation says: &ldquo;Subtract City A&rsquo;s average from each of its observations.&rdquo;</p>
        <p>Suddenly we have:</p>
        <ul>
            <li>Crime becomes: +2, 0, &minus;2</li>
            <li>Staffing becomes: &minus;2, 0, +2</li>
        </ul>
        <p>We are no longer talking about crime and staffing as levels. We are talking about:</p>
        <ul>
            <li><em>when crime is higher than usual for this city</em></li>
            <li><em>when staffing is lower than usual for this city</em></li>
            <li><em>when things shift relative to the city&rsquo;s own baseline</em></li>
        </ul>
        <p>Every city gets the same treatment. Every agency. Every school district. After this step, all that remains is the meaningful variation we can use to identify relationships.</p>
        <p>And it all flows from a simple idea: If something doesn&rsquo;t change for a unit over time, it cannot explain the <em>changes</em> over time. FE removes it.</p>
        <h4><strong>Interpreting FE Results: A Hypothetical Scenario</strong></h4>
        <p>Let&rsquo;s imagine a real example. Suppose you estimate an FE model using annual data on 200 cities from 2010&ndash;2020. Our dependent variable is crime rate (measure: crimes per thousand residents); our independent variable is the size of the police force (total officers per thousand residents). The model is:</p>
        <pre style="background-color: #e0e0e0; padding: 10px; border-radius: 5px; text-align: center; font-family: 'Consolas', 'Courier New', monospace; overflow-x: auto;"><code>
crime<sub>it</sub> = &alpha;<sub>i</sub> + &beta;officers<sub>it</sub> + &epsilon;<sub>it</sub>
</code></pre>
        <p>Stata (or some other program you will eventually use&mdash;but Stata today muahaha) spits out:</p>
        <ul>
            <li>Standard error = 0.10</li>
            <li>p-value = 0.002</li>
        </ul>
        <p>What does this mean? Here&rsquo;s the interpretation (use this for your problem sets): Within the same city, when the number of officers per 1,000 residents is 1 unit higher than the city&rsquo;s usual level, we expect 0.3 fewer crimes per thousand residents than the city&rsquo;s usual crime level, on average.</p>
        <p>Notice what this interpretation emphasizes:</p>
        <ul>
            <li>It is a within-city comparison, not between cities.</li>
            <li>The effect reflects changes, not levels.</li>
            <li>It compares each city to its own history, not to other cities.</li>
        </ul>
        <p>So we are not saying: &ldquo;Cities with more officers have less crime.&rdquo; We are saying:: when <em>this particular city</em> increases staffing above its own long-run norm, crime tends to fall relative to its own long-run norm.&rdquo;</p>
        <p>Got it?</p>
    </div>
    <hr style="border-top: 3px solid orange;" />
    <div class="content-box pad-box-mini border border-trbl border-round" style="background-color: #f8f8f8; padding: 15px;">
        <h3><strong>Running a FE Model in Stata</strong></h3>
        <p>Okay, let&rsquo;s get to the meat of it all. Let&rsquo;s walk through a full example using a small, simulated panel dataset. This will walk you through the BASICS of FE models. More fun will be had in the lab!</p>
        <p>Okay, the dataset&mdash;attached on the module page this week&mdash;has simulated (again, fake) annual data on 200 cities, observed from 2010 through 2019. For each city-year, we have:</p>
        <ul>
            <li><strong>crime</strong>: the violent crime rate per 1,000 residents</li>
            <li><strong>officers</strong>: police officers per 1,000 residents</li>
            <li><strong>city_id</strong>: a unique city identifier</li>
            <li><strong>year</strong>: the calendar year</li>
        </ul>
        <p>Cities naturally differ in their long-term safety levels (some are high-crime, some are low-crime) and we rarely observe all the reasons why. But within each city, staffing levels <em>do</em> rise and fall over time. That makes this an ideal situation for a FE model!</p>
        <p>Again, the dataset (fe_example.dta) is on the module page. Open it up using the use command (or simply double clicking the .dta file).&nbsp;</p>
        <pre style="background-color: #e0e0e0; padding: 10px; border-radius: 5px; text-align: center; font-family: 'Consolas', 'Courier New', monospace; overflow-x: auto;"><code>
use "fe_example.dta", clear
</code></pre>
        <h4><strong>Step 1: Understand the Structure of the Data</strong></h4>
        <p>Unlike the ITS example, where we followed <em>one</em> unit over time, here we&rsquo;re following <em>many</em> units (cities), each observed repeatedly. This structure&mdash;multiple units, each measured over time&mdash;is what makes FE possible. Because every unit (city) has the same number of time periods in the dataset (10 times), we have what we call a &ldquo;balanced&rdquo; dataset. Most won&rsquo;t be balanced the real world. It&rsquo;s fine.</p>
        <ul>
            <li><strong>200 cities</strong></li>
            <li><strong>10 years each</strong></li>
            <li><strong>2,000 total observations</strong></li>
        </ul>
        <h4><strong>Step 2: Declare the Panel Structure</strong></h4>
        <p>The command that we will ultimately use to estimate the FE model&mdash;xtreg&mdash;needs you to tell assure it that its panel data first, and then tell it &ldquo;what the unit is&rdquo; and &ldquo;what the time identifying variable is&rdquo;. So, let&rsquo;s make sure Stata is super clear that :</p>
        <ol>
            <li>The variable &ldquo;city_id&rdquo; identifies units and</li>
            <li>The variable &ldquo;year&rdquo; identifies the time component to our panel data structure</li>
        </ol>
        <pre style="background-color: #e0e0e0; padding: 10px; border-radius: 5px; text-align: center; font-family: 'Consolas', 'Courier New', monospace; overflow-x: auto;"><code>xtset city_id year
</code></pre>
        <p>You should see:</p>
        <pre style="background-color: #e0e0e0; padding: 10px; border-radius: 5px; text-align: center; font-family: 'Consolas', 'Courier New', monospace; overflow-x: auto;"><code>
panel variable: city_id (balanced)

time variable: year, 2010 to 2019
</code></pre>
        <p>Stata is&nbsp; telling you what we already know: we have a balanced panel with 10 observations per city. Gorgeous.<strong>&nbsp;</strong></p>
        <h4><strong>Step 3: Estimate the FE Model</strong></h4>
        <p>We want to estimate the relationship between changes in staffing and changes in crime <strong>within each city</strong>, relative to the city&rsquo;s own long-run baseline.</p>
        <pre style="background-color: #e0e0e0; padding: 10px; border-radius: 5px; text-align: center; font-family: 'Consolas', 'Courier New', monospace; overflow-x: auto;"><code>xtreg crime officers, fe vce(robust)
</code></pre>
        <p>This tells Stata to:</p>
        <ul>
            <li>subtract each city&rsquo;s average crime</li>
            <li>subtract each city&rsquo;s average staffing</li>
            <li>regress the &ldquo;ups and downs&rdquo; of crime on the &ldquo;ups and downs&rdquo; of staffing</li>
        </ul>
        <h4><strong>Step 4: Interpreting the Results</strong></h4>
        <p>Your Stata output should give you:</p>
        <ul>
            <li><strong>&beta; = &ndash;0.29</strong></li>
            <li><strong>SE = 0.03</strong></li>
            <li><strong>p &lt; 0.01</strong></li>
        </ul>
        <p>Here is how we interpret this:</p>
        <p><strong>Within the same city</strong>, when the number of officers per 1,000 residents increases by one unit (relative to that city&rsquo;s usual staffing level) crime decreases by about <strong>0.29 crimes per 1,000 residents</strong> (relative to the city&rsquo;s own usual crime level).</p>
        <p>Key points:</p>
        <ul>
            <li>This is <strong>not</strong> comparing City A to City B.</li>
            <li>This is comparing City A <strong>to itself</strong>, over time.</li>
            <li>All stable city traits (wealth, politics, culture, geography, long-term crime patterns) have been removed.</li>
            <li>The model is identifying the association between <strong>within-city changes</strong> in staffing and <strong>within-city changes</strong> in crime.</li>
        </ul>
    </div>
    <hr style="border-top: 3px solid orange;" />
    <div class="content-box pad-box-mini border border-trbl border-round" style="background-color: #f8f8f8; padding: 15px;">
        <h3><strong>Fixed Effects Assumptions and Limitations</strong></h3>
        <p>Now that you&rsquo;ve seen what FE models are doing&mdash;and why they can be so powerful&mdash;we need to step back and talk honestly about the assumptions that make these models work, and the limits that come along with them. Just like RD and ITS, FE is not magic. It solves some problems beautifully and leaves others untouched. Knowing the difference is what makes you a careful analyst.</p>
        <p>Let&rsquo;s start with the big idea. Fixed Effects works because it removes <strong>everything about a unit that does not change over time</strong>&mdash;its geography, its long-standing politics, its organizational culture, its history, its baseline level of resources. All of those features, which would wreak havoc in a simple cross-sectional regression, are wiped away when we compare a unit to itself over time. That&rsquo;s the heart of FE&rsquo;s identifying strategy.</p>
        <p>But the moment you say that out loud, the first assumption becomes clear: <strong>FE only protects you from confounders that are stable. </strong>Anything that doesn&rsquo;t move over time gets swept into the unit&rsquo;s fixed effect and stops causing trouble.</p>
        <p>But what about confounders that <em>do</em> change over time?</p>
        <p>That&rsquo;s the limitation. FE does <strong>not</strong> protect you from time-varying confounders&mdash;things that shift within a unit and move alongside both your X and your Y. If a city increases its officers at the same time it starts a big social services initiative, both of which influence crime, FE won&rsquo;t separate those changes for you. The model can only adjust for the stable stuff; the moving pieces are still your responsibility as an analyst. This is the same type of &ldquo;omitted variable&rdquo; problem you&rsquo;ve seen before&mdash;except now the omitted variable has to vary within units rather than across them.</p>
        <p>Another way to think about it is: FE solves the &ldquo;City A is richer than City B&rdquo; problem, but it cannot solve the &ldquo;City A introduced two policies at the same time&rdquo; problem.</p>
        <p>A second key assumption embedded in FE is that <strong>the </strong><strong>within-unit variation</strong> you observe is meaningful. FE lives entirely on the ups and downs of a unit over time. If your variable barely changes&mdash;say, officer staffing only wiggles by a tiny amount each year&mdash;FE will technically run, but it won&rsquo;t have much real variation to work with. And if your variable changes in just one dramatic jump that isn&rsquo;t repeated (e.g., one unusual year), then your entire estimate will essentially reflect that single jump. FE assumes that the within-unit variation is real, not just noise, and that it plausibly reflects the causal process you care about.</p>
        <p>There&rsquo;s also a subtle but important assumption that rarely gets highlighted in MPP-level teaching: FE needs the relationship between X and the error term to be clean <strong>not just at one moment, but across the whole time series</strong>. In plainer language, FE assumes that unexpected shocks to the outcome (crime spikes, unusual events, etc.) don&rsquo;t directly cause predictable future changes in the explanatory variable in ways the model can&rsquo;t account for. You don&rsquo;t need to memorize the econometric details, just understand the intuition: if last year&rsquo;s crime jump automatically triggers this year&rsquo;s staffing increase, and that dynamic isn&rsquo;t modeled, it can make FE estimates hard to interpret causally.</p>
        <p>And of course, one of the most visible limitations of FE is the one students notice immediately: <strong>you can&rsquo;t estimate the effect of variables that don&rsquo;t change within units.</strong> If race, gender, founding year, or mission type never change for a given unit, those variables disappear into the fixed effect. FE simply cannot tell you whether, for example, male officers have different job satisfaction than female officers&mdash;not because the effect doesn&rsquo;t exist, but because FE has no variation to work with. But if racial composition of a police department changes over time, then FE can estimate that relationship at the organizational level because the variable actually moves.</p>
        <p>Finally, we should acknowledge that FE throws away all of the &ldquo;between-unit&rdquo; information. That&rsquo;s intentional, but it has tradeoffs. Sometimes between-unit differences are interesting or telling (wealthier cities <em>do</em> tend to have lower crime, for example), but FE discards that pattern entirely. The model focuses only on whether a city becomes safer or more dangerous relative to its own past. This gives you a very clean within-unit comparison, but you lose the bigger structural patterns across units. Whether that&rsquo;s good or bad depends on the question you&rsquo;re trying to answer.</p>
        <p>So, when you stand back, the picture is this: FE gives you an incredibly powerful way to make credible comparisons by holding each unit constant and watching how it changes over time. But it also asks you to be thoughtful. You need enough meaningful within-unit variation. You need to worry about confounders that move with your explanatory variable. You need to be aware that some variables vanish inside the fixed effect. And you need to accept that your estimate is a very particular kind of comparison: within-unit and over time.</p>
        <p>In short, FE solves some big problems, but not all of them. Knowing what it gives you and what it doesn&rsquo;t is the key to using it wisely.</p>
    </div>
    <hr style="border-top: 3px solid orange;" />
    <h3><strong>One Extension: Adding a Time Based FE</strong></h3>
    <p>Up to this point, we&rsquo;ve focused entirely on <strong>unit Fixed Effects</strong>: the part of the model that holds each city (or agency, district, nonprofit) constant by subtracting off its long-run baseline. That alone gets us incredibly far because it removes all of those stable, hard-to-measure characteristics that otherwise confound our analysis.</p>
    <p>But if you think about how public policy works in the real world, units aren&rsquo;t the only thing that change. Time itself often brings big shifts that affect <em>every</em> unit at once. For example, what in a given year, some of the following events could simultaneously affect all of the units!</p>
    <ul>
        <li>A recession hits the whole country.</li>
        <li>A federal law takes effect everywhere.</li>
        <li>A new national policing strategy becomes standard.</li>
        <li>A pandemic reshapes labor markets in every city simultaneously.</li>
    </ul>
    <p>If those kinds of year-to-year shocks are happening while your X and Y are also changing, then even after applying unit Fixed Effects, you may still be comparing apples to oranges, just in a different kinda way. Unit FE removes differences <em>between units</em>, but it does not remove differences <em>between time periods</em>. And those year-level forces can be just as confounding.</p>
    <p>This is where time-based Fixed Effects come in.</p>
    <h4>Time FE: The &ldquo;Year Personality&rdquo;</h4>
    <p>If unit FE give every city its own long-run baseline, time FE give every <em>year</em> its own baseline. Conceptually, it&rsquo;s the same exact idea&mdash;but applied to moments in time rather than units.</p>
    <p>In plain language:</p>
    <p>Time Fixed Effects let the model say: &ldquo;Some years are just different from others, and we should control for that.&rdquo;</p>
    <p>So if 2014 was a low-crime year everywhere, or 2018 saw a nationwide staffing surge, time FE pick that up. Just like unit FE absorb the stable identity of each city, time FE absorb the shared identity of each year.</p>
    <p>This gives us a cleaner comparison. Instead of comparing: City A in 2018 vs. City A in 2017, we&rsquo;re actually comparing: City A in 2018 relative to what 2018 was like for everyone, versus City A in 2017 relative to what 2017 was like for everyone. Subtle, but important.</p>
    <p>TLDR--The model is controlling for:</p>
    <ol>
        <li>differences between cities (unit FE), and</li>
        <li>differences between years (time FE).</li>
    </ol>
    <p>The only thing left&mdash;the signal we care about&mdash;is how changes in X within a city relate to changes in Y within the same city after stripping out the &ldquo;year effect&rdquo; that applies to everyone.</p>
    <h4>Why This Matters in Practice</h4>
    <p>Think back to the ITS module. Remember how powerful it was that the intervention happened at an exact moment in time? Time FE are basically the &ldquo;passive version&rdquo; of that logic: they control for any year-to-year shifts that might otherwise make us think X and Y are related when really both were responding to something else in that specific year.</p>
    <p>Here&rsquo;s a simple story:</p>
    <p>Think back to the dataset we&rsquo;ve been using linking officer staffing to crime. Imagine every city in the dataset experiences a decline in crime in 2014 due to a national policing directive. At the same time, several cities also increased their officer staffing in 2014. Without time FE, the model might see these two things happening in the same year and mistakenly attribute the drop in crime to the staffing increase&mdash;when in reality, crime was falling everywhere.</p>
    <p>With time FE, 2014 gets its own year-level intercept. The model learns: &ldquo;Crime fell everywhere in 2014. That was a year thing, not a city thing.&rdquo; And once that&rsquo;s accounted for, the model looks only at whether staffing changes within a city predict crime changes <em>above and beyond</em> the nationwide trend.</p>
    <p>In other words, time FE protect your model from misinterpreting national or global shocks as city-specific causal effects.&nbsp;</p>
    <h4>How We Add Time FE in Stata</h4>
    <p>The nice thing is: the implementation is trivial. Here is the basic FE model we ran earlier:</p>
    <pre style="background-color: #e0e0e0; padding: 10px; border-radius: 5px; text-align: center;"><code>xtreg crime officers, fe vce(robust)</code></pre>
    <p>To add time FE, you simply include the year indicators:</p>
    <pre style="background-color: #e0e0e0; padding: 10px; border-radius: 5px; text-align: center;"><code>xtreg crime officers i.year, fe vce(robust)</code></pre>
    <p>That&rsquo;s it.</p>
    <p>Under the hood, Stata is now estimating:</p>
    <ul>
        <li>one intercept per city (unit FE)</li>
        <li>one intercept per year (time FE)</li>
        <li>and the coefficient on officers is based on variation that remains after both of those sets of baselines are accounted for</li>
    </ul>
    <p>The interpretation becomes:</p>
    <p>Within the same city, comparing years when staffing is higher than usual to years when staffing is lower than usual, <strong>and holding constant anything that made that year different for all cities</strong>, crime tends to be lower by about .29 crimes per thousand residents.</p>
    <p>It&rsquo;s the same interpretive logic as before. We just added a layer of control that makes the comparison more credible.</p>
    <hr style="border-top: 3px solid orange;" />
    <div class="content-box pad-box-mini border border-trbl border-round" style="background-color: #f8f8f8; padding: 15px;">
        <h3><strong>Moving Forward</strong></h3>
        <p>OKAY. This module is too long. Sorry. I tried to cut and failed.</p>
        <p>But hopefully you&rsquo;ve gotten the point. You seen the full arc of Fixed Effects: why we use it, what problem it solves, how the model actually works, how to interpret it, and how to extend it with time fixed effects when we&rsquo;re dealing with shocks or trends that affect every unit at once. You&rsquo;ve also seen the FE model in action on a panel dataset and walked through the Stata commands you&rsquo;ll use most often in practice.</p>
        <p>Now the real learning happens: actually <em>doing</em> it. Welcome, lab.</p>
        <p>In the upcoming lab, you&rsquo;ll work with some real data and learn to run code yourself. You&rsquo;ll:</p>
        <ul>
            <li>explore a real panel structure,</li>
            <li>declare the panel with xtset,</li>
            <li>run the naive, pooled regression (and see why it&rsquo;s misleading),</li>
            <li>run the unit FE model,</li>
            <li>interpret the &ldquo;within-unit&rdquo; meaning of the FE coefficient,</li>
            <li>and then add time fixed effects to see how the estimate responds when we start absorbing the year-to-year shocks that affect everyone.</li>
            <li>Maybe some figures (I haven&rsquo;t made the lab yet)</li>
        </ul>
        <p>By the end of lab, these commands will feel natural. More importantly, the logic behind them will start to click: the FE model <em>does</em> exactly what we&rsquo;ve been saying: it holds the unit constant, compares it to itself, and pulls out the change-based relationship we care about.</p>
        <p>And in two modules&mdash;the one after next week&rsquo;s lab&mdash;the pieces you&rsquo;ve learned here will slot directly into a much bigger framework (one you&rsquo;ve likely heard about if you&rsquo;ve work with and/or taken enough classes with public policy folks and/or economists): <strong>Difference-in-Differences (DiD)</strong>. If FE is the grammar, DiD is one of the most important &ldquo;sentences&rdquo; ever written in that grammar. DiD puts together unit FE, time FE, and a carefully structured treatment indicator to evaluate policies that turn on at different times for different units.</p>
        <p>You&rsquo;ll see quickly that you already know half the model&mdash;unit FE and time FE&mdash;before we even introduce DiD. That&rsquo;s super intentional. By understanding the backbone this week, you&rsquo;ll be in an excellent position to understand why DiD works, what it assumes, and how to diagnose whether those assumptions hold.</p>
        <p>So for now: take a deep breath, open the dataset, and get ready to poke around. FE is one of the most widely used tools in applied public policy research for a reason, and by the end of this week, you&rsquo;ll understand exactly why.</p>
    </div>
</div>